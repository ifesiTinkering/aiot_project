# Argument Resolver System

Complete system for recording, resolving, and browsing arguments using Raspberry Pi and AI.

## ğŸ—ï¸ Architecture (Simplified!)

```
Raspberry Pi:
  â†’ Records Audio (30 seconds)
  â†’ Processes Locally (speaker ID, transcription, fact-check)
  â†’ Saves to local database
  â†’ Sends results to laptop
                â†“
Laptop:
  â†’ Receives results (results_receiver.py)
  â†’ Stores in local database
  â†’ Browse via web interface (browse_arguments.py)
```

**Benefits:**
- âœ… Pi does all the heavy processing
- âœ… Works offline (saves locally even if laptop is unavailable)
- âœ… Laptop only needs to receive and display results
- âœ… Much simpler architecture

## ğŸ“ File Structure

```
aiot_project/
â”œâ”€â”€ pi_processor.py             # ğŸ†• Main script for Raspberry Pi (records + processes)
â”œâ”€â”€ results_receiver.py         # ğŸ†• Laptop receives results from Pi
â”œâ”€â”€ browse_arguments.py         # Web UI to view past arguments
â”œâ”€â”€ storage.py                  # Database manager (JSON-based)
â”œâ”€â”€ .env                        # API keys (POE_API_KEY, HUGGINGFACE_TOKEN, LAPTOP_IP)
â”œâ”€â”€ .env.example                # Template for environment variables
â”œâ”€â”€ arguments_db/               # Data storage (on both Pi and laptop)
â”‚   â”œâ”€â”€ arguments.json          # Index of all arguments
â”‚   â””â”€â”€ arguments/
â”‚       â”œâ”€â”€ 20251112_182945/    # Each argument in its own folder
â”‚       â”‚   â”œâ”€â”€ audio.wav       # Original recording
â”‚       â”‚   â”œâ”€â”€ metadata.json   # Structured data
â”‚       â”‚   â””â”€â”€ transcript.txt  # Full conversation text
â”‚       â””â”€â”€ ...
â”œâ”€â”€ audio_processor.py          # (Legacy - old architecture)
â”œâ”€â”€ argument_resolver.py        # (Legacy - old architecture)
â””â”€â”€ record_and_send.py          # (Legacy - old architecture)
```

## ğŸš€ How to Use (New Simplified Architecture)

### Setup (One-time)

**1. On Raspberry Pi:**
```bash
cd ~
git clone https://github.com/ifesiTinkering/aiot_project.git
cd aiot_project

# Create .env file
nano .env
# Add these lines:
POE_API_KEY=your_poe_api_key
HUGGINGFACE_TOKEN=your_huggingface_token
LAPTOP_IP=172.22.129.179

# Install dependencies
pip install python-dotenv whisper torch torchaudio pyannote.audio fastapi_poe requests
```

**2. On Laptop:**
```bash
cd /Users/dimmaonubogu/aiot_project

# .env file already exists with your tokens
# Just verify LAPTOP_IP is correct
```

---

### Running the System

**Step 1: Start Results Receiver on Laptop (optional)**
```bash
cd /Users/dimmaonubogu/aiot_project
python results_receiver.py
```
- Runs on port 7864
- Receives processed results from Pi
- Not required - Pi saves locally even if laptop is offline

**Step 2: Record & Process on Raspberry Pi**
```bash
cd ~/aiot_project
python3 pi_processor.py
```

**This will:**
- âœ… Check USB microphone
- âœ… Record 30 seconds of audio
- âœ… Identify speakers using diarization
- âœ… Transcribe conversation with Whisper
- âœ… Save results locally on Pi (`/home/ifesiras/arguments_db/`)
- âœ… Send results to laptop (if available)
- âœ… Display processing summary

**Step 3: Browse Results on Laptop**
```bash
cd /Users/dimmaonubogu/aiot_project
python browse_arguments.py
```

**Opens web interface at:** http://127.0.0.1:7863

**Features:**
- Browse all arguments sorted by date
- View full transcripts with timestamps
- Listen to audio playback
- Search by keywords
- View statistics

## ğŸ“Š Data Storage Format

Each argument is stored with:

### metadata.json
```json
{
  "id": "20251112_182945",
  "title": "AI Job Displacement by 2030",
  "timestamp": "2025-11-12T18:29:45Z",
  "duration_seconds": 30,
  "num_speakers": 2,
  "speakers": {
    "SPEAKER_00": {
      "transcript": "I think AI will...",
      "word_count": 145
    },
    "SPEAKER_01": {
      "transcript": "That's not true...",
      "word_count": 167
    }
  },
  "verdict": {
    "winner": "SPEAKER_01",
    "confidence": 75,
    "reasoning": "..."
  },
  "full_verdict_text": "## VERDICT: SPEAKER_01\n## CONFIDENCE: 75%\n..."
}
```

### audio.wav
Original audio recording (16kHz, mono, WAV format)

### transcript.txt
Full conversation with timestamps:
```
[0.0s] SPEAKER_00: I think AI will replace all jobs by 2030
[5.2s] SPEAKER_01: That's not true, studies show...
[12.4s] SPEAKER_00: But look at what happened with...
```

## ğŸ”Œ API Endpoints

### audio_processor.py (port 7862)

**POST /upload**
- Receives audio file
- Processes and stores argument
- Returns processing results

**GET /**
- Status check
- Database statistics

**GET /arguments**
- List all stored arguments

**GET /arguments/{argument_id}**
- Get specific argument details

## ğŸ› ï¸ Dependencies

Already installed:
- `gradio` - Web interfaces
- `whisper` - Speech transcription
- `pyannote.audio` - Speaker diarization
- `fastapi` - API server
- `uvicorn` - ASGI server
- `requests` - HTTP client
- `torch` - ML framework

## ğŸ“ Workflow Example

1. **Record**: Two people argue about climate change on Raspberry Pi
2. **Send**: Pi sends 30-second audio to laptop
3. **Process**: Laptop automatically:
   - Identifies 2 speakers
   - Transcribes what each said
   - Fact-checks claims via Polymarket & web search
   - Determines winner based on evidence
4. **Store**: Saves to `arguments_db/20251112_183045/`
5. **Browse**: View results anytime in web interface

## ğŸ”§ Configuration

All configuration is done via the `.env` file:

```bash
# .env file (create on both Pi and laptop)
POE_API_KEY=your_poe_api_key_here
HUGGINGFACE_TOKEN=your_huggingface_token_here
LAPTOP_IP=172.22.129.179  # Update when laptop IP changes
```

### Update Laptop IP (if needed)

If your laptop's IP changes, update `.env` on the Pi:

```bash
# On Pi
cd ~/aiot_project
nano .env
# Change LAPTOP_IP to your new IP
```

### Adjust Recording Duration

Edit `pi_processor.py` on Pi:
```python
RECORD_DURATION = 30  # Change to 60 for 1 minute, etc.
```

### Ports Used

- `results_receiver.py`: Port 7864 (receives results from Pi)
- `browse_arguments.py`: Port 7863 (web interface)

## ğŸ¯ Key Features

âœ… **Pi-Based Processing**: All heavy processing on Raspberry Pi
âœ… **Offline Capable**: Works even if laptop is unavailable
âœ… **Speaker Identification**: Knows who said what
âœ… **Automatic Transcription**: Using OpenAI Whisper
âœ… **Persistent Storage**: Saved on both Pi and laptop
âœ… **Web Interface**: Easy browsing and search
âœ… **Audio Playback**: Listen to original recordings
âœ… **Sync to Laptop**: Optional result syncing for viewing

## ğŸ“ˆ Future Enhancements

Possible additions:
- Email notifications when arguments are resolved
- Export to PDF/CSV
- Speaker name assignment (instead of SPEAKER_00)
- Real-time processing status updates
- Mobile app interface
- Voice commands to start recording

---

**System Status:**
- âœ… Storage system ready
- âœ… Audio processor ready
- âœ… Browse interface ready
- âœ… Raspberry Pi configured
- âœ… End-to-end tested

**Ready to use!**
